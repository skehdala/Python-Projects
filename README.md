# Trades data analysis
I am performing walk forward testing of a trading algorithm that I wrote.
The goal of this analysis is to draw some meaningfull conclusions about the performance of this account.

For the time being I decided not to share the dataset.

This is still a work in progress.
```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from scipy.stats import skew, kurtosis, geom, rv_histogram, powerlaw, expon
from datetime import timedelta
```
```python
figsize = (4,3)
```
# Trades data analysis
I am performing walk forward testing of a trading algorithm that I wrote.
The goal of this analysis is to draw some meaningfull conclusions about the performance of this account.

For the time being I decided not to share the dataset.

This is still a work in progress.

# The data
The data contains information on 92 trades performed by my trading algorithm.
```python
path = "/home/dev/Desktop/OrdersReport.csv"
```
```python
raw = pd.read_csv(path, index_col=None, header=0, sep=",")
```
```python
df = raw.copy()
```
The available columns are listed below:
```python
df.info()
```
![image](https://github.com/user-attachments/assets/307940c2-a5a2-488b-bcaa-32b43778786d)

The names of columns are fairly self explanatory.
However I feel I should provide more information on these:

- 'Ticket' is generated by the broker and is of no meaning.
- 'Magic' column is used to distinguish between trading algorithms.
- 'Comment' will be used to determine the reason why a trade was closed.

## Data preparation
### Data checks
The data is generated by a script written in MQL4.
During the setup of the trading algorithms I made a mistake and entered the wrong 'magic' number into the algorithm.
To rectify this mistake I switch the magic number to the correct value.
```python
df.loc[df['Magic'] == 12345, 'Magic'] = 4444
```
I expect that there are no missing values.
```python
df.isna().sum()
```
![image](https://github.com/user-attachments/assets/374ff644-4489-4fa7-b1ed-c18d34ed47d9)

I then check for constant columns. I excpect the 'Commission' column to be all zeroes.
```python
df.var() == 0
```
![image](https://github.com/user-attachments/assets/eaa17ec3-b048-4c09-8bf3-f292b12d955f)

Indeed, the commision columns is all zeroes.
```python
df['Commission'][0]
```
0

I expect that all open prices are positive, so I count how many are negative.
```python
df[df['Open Price'] <= 0]['Open Price'].count()
```
0

The same should apply to close prices.
```python
df[df['Close Price'] <= 0]['Close Price'].count()
```
0

Lots also should be positive.
```python
df[df['Lots'] <= 0]['Lots'].count()
```
0

### Transformations
For aesthetic reasons, I strip the names of symbols from "+" and ".".
```python
df['Symbol'] = df['Symbol'].apply(lambda x: x.replace("+", ""))
df['Symbol'] = df['Symbol'].apply(lambda x: x.replace(".", ""))
```
Convert columns with timestamps from strings to datetimes.
```python
df['Open Datetime'] = pd.to_datetime(df['Open Datetime'])
df['Close Datetime'] = pd.to_datetime(df['Close Datetime'])
```
Chronological order is of utmost importance since I shall be performing running calculations later.
```python
df = df.sort_values('Open Datetime')
df = df.reset_index(drop=True)
````
### New columns
In this section I add new columns to the dataset.
I shall definitely want to perform aggregations by time so I add the necessary columns.
I start with extracting the date, hour and day of week from the "Open Datetime" column.
```python
df['Open Date'] = df['Open Datetime'].dt.date
df['Open Hour'] = df['Open Datetime'].dt.hour    
df['Open Day'] = df['Open Datetime'].dt.day_name()
df['Open Datetime Seconds'] = pd.to_datetime(df['Open Datetime'], origin='unix').astype('int')
```
I extract the same information as above for the "Close Datetime" column.
```python
df['Close Date'] = df['Close Datetime'].dt.date
df['Close Hour'] = df['Close Datetime'].dt.hour    
df['Close Day'] = df['Close Datetime'].dt.day_name()
df['Close Datetime Seconds'] = pd.to_datetime(df['Close Datetime'], origin='unix').astype('int')
```
I calculate the duration of individual trades. The final value is in minutes.
```python
df['Duration'] = (df['Close Datetime'] - df['Open Datetime'])
df['Duration'] = df['Duration'].apply(lambda x: x.total_seconds() / 60)
```
I create a new column that is equall to the net profit from a trade.
```python
df['Profit'] = df['Profit'] + df['Swap'] + df['Commission']
```
I need a 'Profit Per Lot' column because different trades have different lot sizes.
```python
df['Profit Per Lot'] = df['Profit'] / ( df['Lots'] / 0.01)
```
I add two columns to describe the direction of a trade.
```python
df['Order Type'] = df['Type'].apply(lambda x: "Buy" if x == 0 else "Sell")
df['Direction'] = df['Type'].apply(lambda x: 1 if x == 0 else -1)
```
I extract the reason why a trade was closed from the 'Comment' column. The reason for closure is added by my broker to the end of my comment:
```python
df['Comment'][0]
```
![image](https://github.com/user-attachments/assets/db8dc70f-96ca-4b86-9a98-f93ab387022e)

In order to extract the reason for closure I search for specific strings in the comment.
```python
df['Stop Loss Hit'] = df['Comment'].apply(lambda x: 1 if "[[sl]]" in x else 0)
df['Take Profit Hit'] = df['Comment'].apply(lambda x: 1 if "[[tp]]" in x else 0)
```
I calculate the percentage difference between the take profit and the stop loss columns. I define a helper function first:
```python
def stops_dist(x):
    
    if x[2] == 1:                
        return (x[0] / x[1] - 1) * 100    
    else:    
        return (x[1] / x[0] - 1) * 100
```
It is then applied to a subset of the original data.
```python
df['Stops Distance'] = df[['Take Profit', 'Stop Loss', 'Direction']].apply(stops_dist, axis=1)
```
### Useless columns
I delete unwanted columns:

- Ticket - Generated by the broker for their internal purposes.
- Commission - Constant column equall to zero.
- Comment - Information was extracted.
- Type - Information was extracted.
- Take Profit - Information was extracted and is not relevant to this analysis.
- Stop Loss - Information was extracted and is not relevant to this analysis.
```python
unwanted = ['Ticket', 
            'Commission',             
            'Comment', 
            'Type', 
            'Take Profit', 
            'Stop Loss']

df.drop(unwanted, axis=1, inplace=True)
```
The shape of the original data was:
```python
raw.shape
```
(92,15)

After cleaning the shape is:
```python
df.shape
```
(92, 24)

The clean data looks like this:
```python
df.head()
```
![image](https://github.com/user-attachments/assets/59899d0e-feb1-4ddc-91e8-5084c4a72255)

### The basics

I'm going to start the analysis by computing basic statistics the should interest any algorithmic trader.
Trading started on:
```python
start = df['Open Date'].min()
str(start)
```
'2020-05-19'

The last trade in the data was closed on:
```python
stop = df['Close Date'].max()
str(stop)
```
'2020-06-16'

That means the algorithms traded for nearly a month.
```python
str(stop - start)
```
'28 days, 0:00:00'

Trades over the period in question:
```python
df.shape[0]
```
92

### Profit

#### Total profit

Over the period in question the algorithms achieved a profit of:
```python
np.round(df['Profit'].sum(), 2)
```
118.02 

### Total profit by market

As can be seen the bulk of the profit comes from 'USDCHF'.
```python
df_symbol = df[['Symbol', 'Profit']].groupby(['Symbol'], as_index=False).sum()

plt.figure(figsize=figsize)
plt.bar(df_symbol['Symbol'], df_symbol['Profit'])
plt.xticks(df_symbol['Symbol'], rotation=90)
plt.ylabel('Profit (zł)')
plt.xlabel('Symbol')
plt.show()
```
![image](https://github.com/user-attachments/assets/0165fe65-af60-47fa-a9c9-f36230b6f2e2)

### Total profit by market and trade direction

The most money was made by shorting 'USDCHF'. The most money was lost buying 'US500'.
```python
df_mkt = df[['Symbol', 'Order Type', 'Direction', 'Profit']]
df_mkt = df_mkt.groupby(['Symbol', 'Order Type'], as_index=False)
df_mkt = df_mkt.agg({"Direction": [np.sum], "Profit": [np.sum]})
df_mkt.columns = df_mkt.columns.droplevel(1)
df_mkt['Direction'] = np.abs(df_mkt['Direction'])
df_mkt = df_mkt.rename(columns={"Direction" : "Number of trades"})
df_mkt.sort_values('Profit', ascending=False)
```
![image](https://github.com/user-attachments/assets/c6bcbe51-9e3a-4bcc-9ed7-9c257d0b078c)

### Best days
The 3 best days were:
```python
df_cdate = df[['Close Date', 'Profit']].groupby(['Close Date'], as_index=False).sum()
df_cdate.sort_values('Profit', ascending=False).head(3)
```
![image](https://github.com/user-attachments/assets/3eeaf65c-5f79-4e02-b9fe-4a8e2a7ad9f9)

### Worst days
The worst 3 days were:
```python
df_cdate.sort_values('Profit', ascending=True).head(3)
```
![image](https://github.com/user-attachments/assets/a882b96e-4404-4580-bf5c-14121bd65b56)

### Costs
Amount of swap paid:
```python
np.sum(df['Swap'])
```
-7.6

### Profit Per Lot
Since the trades vary in lot size it makes more sense to look at 'Profit Per Lot' than at 'Profit'.

### Profit Per Lot histogram
As can be seen the distribution of 'Profit Per Lot' is nothing like a normal distribution:
```python
width = 400
height = 400
dpi = 100

plt.figure(figsize=(width/dpi, height/dpi))
plt.hist(df['Profit Per Lot'])
plt.ylabel('Frequency')
plt.xlabel('Profit Per Lot (zł)')
plt.title('Profit Per Lot histogram', fontsize=18)
plt.tight_layout()
plt.savefig('./img/profit_histogram.png')
plt.show()
```

![image](https://github.com/user-attachments/assets/a9b666a5-ab9d-4359-82cb-388f33636f7f)

https://github.com/shsarv/Data-Analytics-Projects-in-python/blob/main/trading-results/Trading%20Results%20Analysis.ipynb
