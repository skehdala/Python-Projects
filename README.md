# Trades data analysis
I am performing walk forward testing of a trading algorithm that I wrote.
The goal of this analysis is to draw some meaningfull conclusions about the performance of this account.

For the time being I decided not to share the dataset.

This is still a work in progress.
```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from scipy.stats import skew, kurtosis, geom, rv_histogram, powerlaw, expon
from datetime import timedelta
```
```python
figsize = (4,3)
```
# Trades data analysis
I am performing walk forward testing of a trading algorithm that I wrote.
The goal of this analysis is to draw some meaningfull conclusions about the performance of this account.

For the time being I decided not to share the dataset.

This is still a work in progress.

# The data
The data contains information on 92 trades performed by my trading algorithm.
```python
path = "/home/dev/Desktop/OrdersReport.csv"
```
```python
raw = pd.read_csv(path, index_col=None, header=0, sep=",")
```
```python
df = raw.copy()
```
The available columns are listed below:
```python
df.info()
```
![image](https://github.com/user-attachments/assets/307940c2-a5a2-488b-bcaa-32b43778786d)

The names of columns are fairly self explanatory.
However I feel I should provide more information on these:

- 'Ticket' is generated by the broker and is of no meaning.
- 'Magic' column is used to distinguish between trading algorithms.
- 'Comment' will be used to determine the reason why a trade was closed.

## Data preparation
### Data checks
The data is generated by a script written in MQL4.
During the setup of the trading algorithms I made a mistake and entered the wrong 'magic' number into the algorithm.
To rectify this mistake I switch the magic number to the correct value.
```python
df.loc[df['Magic'] == 12345, 'Magic'] = 4444
```
I expect that there are no missing values.
```python
df.isna().sum()
```
![image](https://github.com/user-attachments/assets/374ff644-4489-4fa7-b1ed-c18d34ed47d9)

I then check for constant columns. I excpect the 'Commission' column to be all zeroes.
```python
df.var() == 0
```
![image](https://github.com/user-attachments/assets/eaa17ec3-b048-4c09-8bf3-f292b12d955f)

Indeed, the commision columns is all zeroes.
```python
df['Commission'][0]
```
0

I expect that all open prices are positive, so I count how many are negative.
```python
df[df['Open Price'] <= 0]['Open Price'].count()
```
0

The same should apply to close prices.
```python
df[df['Close Price'] <= 0]['Close Price'].count()
```
0

Lots also should be positive.
```python
df[df['Lots'] <= 0]['Lots'].count()
```
0

### Transformations
For aesthetic reasons, I strip the names of symbols from "+" and ".".
```python
df['Symbol'] = df['Symbol'].apply(lambda x: x.replace("+", ""))
df['Symbol'] = df['Symbol'].apply(lambda x: x.replace(".", ""))
```
Convert columns with timestamps from strings to datetimes.
```python
df['Open Datetime'] = pd.to_datetime(df['Open Datetime'])
df['Close Datetime'] = pd.to_datetime(df['Close Datetime'])
```
Chronological order is of utmost importance since I shall be performing running calculations later.
```python
df = df.sort_values('Open Datetime')
df = df.reset_index(drop=True)
````
### New columns
In this section I add new columns to the dataset.
I shall definitely want to perform aggregations by time so I add the necessary columns.
I start with extracting the date, hour and day of week from the "Open Datetime" column.
```python
df['Open Date'] = df['Open Datetime'].dt.date
df['Open Hour'] = df['Open Datetime'].dt.hour    
df['Open Day'] = df['Open Datetime'].dt.day_name()
df['Open Datetime Seconds'] = pd.to_datetime(df['Open Datetime'], origin='unix').astype('int')
```
I extract the same information as above for the "Close Datetime" column.
```python
df['Close Date'] = df['Close Datetime'].dt.date
df['Close Hour'] = df['Close Datetime'].dt.hour    
df['Close Day'] = df['Close Datetime'].dt.day_name()
df['Close Datetime Seconds'] = pd.to_datetime(df['Close Datetime'], origin='unix').astype('int')
```
I calculate the duration of individual trades. The final value is in minutes.
```python
df['Duration'] = (df['Close Datetime'] - df['Open Datetime'])
df['Duration'] = df['Duration'].apply(lambda x: x.total_seconds() / 60)
```
I create a new column that is equall to the net profit from a trade.
```python
df['Profit'] = df['Profit'] + df['Swap'] + df['Commission']
```
I need a 'Profit Per Lot' column because different trades have different lot sizes.
```python
df['Profit Per Lot'] = df['Profit'] / ( df['Lots'] / 0.01)
```
I add two columns to describe the direction of a trade.
```python
df['Order Type'] = df['Type'].apply(lambda x: "Buy" if x == 0 else "Sell")
df['Direction'] = df['Type'].apply(lambda x: 1 if x == 0 else -1)
```
I extract the reason why a trade was closed from the 'Comment' column. The reason for closure is added by my broker to the end of my comment:
```python
df['Comment'][0]
```
![image](https://github.com/user-attachments/assets/db8dc70f-96ca-4b86-9a98-f93ab387022e)

In order to extract the reason for closure I search for specific strings in the comment.
